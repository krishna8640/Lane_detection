{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce54642-8586-44a8-861a-e21ce081f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Convert to HSV color space to isolate yellow and white colors\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define color thresholds for yellow\n",
    "    yellow_lower = np.array([15, 100, 100], dtype=np.uint8)\n",
    "    yellow_upper = np.array([35, 255, 255], dtype=np.uint8)\n",
    "    \n",
    "    # Create a mask for yellow\n",
    "    mask_yellow = cv2.inRange(hsv, yellow_lower, yellow_upper)\n",
    "    \n",
    "    # Convert the frame to grayscale for white line detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply a binary threshold to detect white lines\n",
    "    _, mask_white = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Combine the yellow and white masks\n",
    "    combined_mask = cv2.bitwise_or(mask_yellow, mask_white)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    threshold_low = 10\n",
    "    threshold_high = 210\n",
    "    edges = cv2.Canny(combined_mask, threshold_low, threshold_high)\n",
    "    \n",
    "    # Define vertices for region of interest (ROI)\n",
    "    height, width = frame.shape[:2]\n",
    "    vertices = np.array([[(249, 410), (367, 359), (407, 357), (504, 409)]], dtype=np.int32)\n",
    "    \n",
    "    mask = np.zeros_like(edges)   \n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "    \n",
    "    # Hough Line Transform to detect both straight lines and line segments\n",
    "    rho = 2            # distance resolution in pixels \n",
    "    theta = np.pi/180  # angular resolution in radians \n",
    "    threshold = 20     # minimum number of votes \n",
    "    min_line_len = 20  # minimum number of pixels making up a line\n",
    "    max_line_gap = 300  # maximum gap in pixels between connectable line segments    \n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    \n",
    "    # Create an empty black image to draw lines on\n",
    "    line_image = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:      \n",
    "                cv2.line(line_image, (x1, y1), (x2, y2), [0, 255, 0], 10)  # Green color [0, 255, 0] and thicker line (10)\n",
    "    \n",
    "    # Combine the original frame with the line image\n",
    "    α = 1  # Weight of the original image\n",
    "    β = 1  # Weight of the lines image\n",
    "    γ = 0  # Scalar added to each sum\n",
    "    Image_with_lines = cv2.addWeighted(frame, α, line_image, β, γ)\n",
    "    \n",
    "    return Image_with_lines\n",
    "\n",
    "def main():\n",
    "    input_video_path = r'C:\\Users\\Omen\\Downloads\\Lane detection lectures\\test_videos\\02d5e1be-cb00355e.mov'  # Path to the input video\n",
    "    output_video_path = r'C:\\Users\\Omen\\Downloads\\Lane detection lectures\\test_videos_output\\02d5e1be-cb00355e.mov12345.mov'  # Path to save the output video\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        processed_frame = process_frame(frame)\n",
    "        out.write(processed_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b434929-3e78-49b6-87cc-aedede968ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the list of points (ROI vertices)\n",
    "roi_vertices = [(20, 460), (340, 300), (460, 300), (740, 460)]\n",
    "selected_vertex = -1  # Index of the selected vertex\n",
    "radius = 5  # Radius for showing the vertices\n",
    "dragging = False  # Flag to indicate if dragging is occurring\n",
    "\n",
    "def draw_polygon(image, vertices):\n",
    "    \"\"\" Draw the polygon with the current vertices on the image \"\"\"\n",
    "    # Draw the ROI\n",
    "    pts = np.array(vertices, np.int32)\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    cv2.polylines(image, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    \n",
    "    # Draw the vertices\n",
    "    for (x, y) in vertices:\n",
    "        cv2.circle(image, (x, y), radius, (0, 0, 255), -1)\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global roi_vertices, selected_vertex, dragging\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Check if the mouse is clicked near any of the vertices\n",
    "        for i, (vx, vy) in enumerate(roi_vertices):\n",
    "            if abs(x - vx) < radius and abs(y - vy) < radius:\n",
    "                selected_vertex = i\n",
    "                dragging = True\n",
    "                break\n",
    "    \n",
    "    elif event == cv2.EVENT_MOUSEMOVE and dragging:\n",
    "        # Drag the selected vertex\n",
    "        if selected_vertex != -1:\n",
    "            roi_vertices[selected_vertex] = (x, y)\n",
    "    \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # Release the selected vertex\n",
    "        dragging = False\n",
    "        selected_vertex = -1\n",
    "\n",
    "def interactive_roi_selection(image):\n",
    "    global roi_vertices\n",
    "    \n",
    "    # Create a copy of the image for displaying\n",
    "    display_image = image.copy()\n",
    "    \n",
    "    # Create a window and set the mouse callback function\n",
    "    cv2.namedWindow(\"Interactive ROI Selection\")\n",
    "    cv2.setMouseCallback(\"Interactive ROI Selection\", mouse_callback)\n",
    "    \n",
    "    while True:\n",
    "        # Display the image with the current ROI\n",
    "        temp_image = display_image.copy()\n",
    "        draw_polygon(temp_image, roi_vertices)\n",
    "        cv2.imshow(\"Interactive ROI Selection\", temp_image)\n",
    "        \n",
    "        # Break the loop when the user presses the 'q' key\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return roi_vertices\n",
    "\n",
    "def main():\n",
    "    input_video_path = r'C:\\Users\\Omen\\Downloads\\Lane detection lectures\\test_videos\\02d5e1be-cb00355e.mov'  # Path to the input video\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Unable to open video at {input_video_path}. Please check the file path.\")\n",
    "        return\n",
    "    \n",
    "    # Read the first frame (or any specified frame)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read a frame from the video.\")\n",
    "        return\n",
    "    \n",
    "    # Run the interactive ROI selection tool on the extracted frame\n",
    "    updated_vertices = interactive_roi_selection(frame)\n",
    "    \n",
    "    print(\"Updated ROI vertices:\")\n",
    "    print(updated_vertices)\n",
    "    \n",
    "    # Now, you can use `updated_vertices` in your processing code\n",
    "    # Convert the vertices to a NumPy array for further processing\n",
    "    vertices = np.array([updated_vertices], dtype=np.int32)\n",
    "\n",
    "    # Example of using the vertices in a mask\n",
    "    mask = np.zeros_like(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    \n",
    "    # Show the masked region\n",
    "    masked_image = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    cv2.imshow(\"Masked Image\", masked_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
